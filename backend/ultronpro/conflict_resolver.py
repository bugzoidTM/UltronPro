"""Resolu√ß√£o Autom√°tica de Conflitos via LLM.

Quando h√° conflitos de conhecimento (mesma tripla com objetos diferentes),
a LLM analisa as evid√™ncias e decide qual variante √© mais prov√°vel.

Estrat√©gias:
1. An√°lise de evid√™ncias internas (experi√™ncias, fontes, trust)
2. Consulta externa (Wikipedia, busca)
3. Racioc√≠nio l√≥gico (coer√™ncia com outras triplas)
4. Escalada para humano se incerteza alta
"""
from __future__ import annotations

import json
import time
from dataclasses import dataclass
from typing import Any

from ultronpro import llm


@dataclass
class ResolutionResult:
    """Resultado de uma tentativa de resolu√ß√£o."""
    resolved: bool
    chosen_object: str | None = None
    confidence: float = 0.0
    reasoning: str = ""
    strategy: str = "llm_analysis"
    needs_human: bool = False
    error: str | None = None


# Threshold de confian√ßa para resolu√ß√£o autom√°tica
AUTO_RESOLVE_THRESHOLD = 0.7
# M√°ximo de conflitos a resolver por ciclo
MAX_CONFLICTS_PER_CYCLE = 3
# Cooldown entre tentativas no mesmo conflito (horas)
# reduzido para permitir auto-corre√ß√£o cont√≠nua sem esperar clique humano
RETRY_COOLDOWN_HOURS = 1.0


def _build_analysis_prompt(conflict: dict, variants: list[dict], context: str = "") -> str:
    """Constr√≥i prompt para an√°lise de conflito."""
    subject = conflict.get("subject", "?")
    predicate = conflict.get("predicate", "?")
    
    variants_text = "\n".join([
        f"  - \"{v.get('object', '?')}\" (confian√ßa: {v.get('confidence', 0):.2f}, trust_fonte: {v.get('source_trust', 0.5):.2f}, visto {v.get('seen_count', 0)}x)"
        for v in variants
    ])
    
    prompt = f"""Voc√™ √© um √°rbitro de conhecimento. Analise este conflito e decida qual variante √© mais prov√°vel.

CONFLITO:
Sujeito: {subject}
Predicado: {predicate}

VARIANTES:
{variants_text}

{f"CONTEXTO ADICIONAL: {context}" if context else ""}

INSTRU√á√ïES:
1. Analise cada variante com base em:
   - Coer√™ncia l√≥gica
   - Conhecimento geral
   - Confian√ßa e frequ√™ncia de observa√ß√£o
2. Escolha a variante mais prov√°vel
3. Se n√£o houver informa√ß√£o suficiente para decidir, diga "INCERTO"

Responda em JSON:
{{
  "chosen": "<objeto escolhido ou INCERTO>",
  "confidence": <0.0 a 1.0>,
  "reasoning": "<explica√ß√£o breve do racioc√≠nio>"
}}"""
    
    return prompt


def _build_synthesis_prompt(conflict: dict, variants: list[dict]) -> str:
    """Constr√≥i prompt para s√≠ntese (quando ambas as variantes podem ser parcialmente corretas)."""
    subject = conflict.get("subject", "?")
    predicate = conflict.get("predicate", "?")
    
    variants_text = "\n".join([
        f"  - \"{v.get('object', '?')}\""
        for v in variants
    ])
    
    prompt = f"""Analise se estas variantes conflitantes podem ser SINTETIZADAS em uma √∫nica resposta mais completa.

CONFLITO:
"{subject}" {predicate} ...

VARIANTES:
{variants_text}

INSTRU√á√ïES:
- Se as variantes s√£o mutuamente exclusivas (apenas uma pode ser verdade), responda "EXCLUSIVE"
- Se podem ser combinadas/sintetizadas, proponha uma s√≠ntese

Responda em JSON:
{{
  "can_synthesize": true/false,
  "synthesis": "<s√≠ntese proposta ou null>",
  "reasoning": "<explica√ß√£o>"
}}"""
    
    return prompt


def _parse_llm_response(response: str) -> dict:
    """Tenta extrair JSON da resposta da LLM."""
    try:
        # Limpa markdown se presente
        text = response.strip()
        if text.startswith("```"):
            lines = text.split("\n")
            text = "\n".join(lines[1:-1] if lines[-1].strip() == "```" else lines[1:])
        
        return json.loads(text)
    except Exception:
        return {}


def analyze_conflict(
    conflict: dict,
    variants: list[dict],
    related_triples: list[dict] | None = None,
    external_context: str | None = None,
) -> ResolutionResult:
    """Analisa um conflito e tenta resolv√™-lo via LLM.
    
    Args:
        conflict: Dados do conflito (subject, predicate, etc.)
        variants: Lista de variantes com object, confidence, seen_count
        related_triples: Triplas relacionadas para contexto
        external_context: Contexto externo (busca, Wikipedia, etc.)
    
    Returns:
        ResolutionResult com a decis√£o
    """
    if not variants or len(variants) < 2:
        return ResolutionResult(resolved=False, error="Menos de 2 variantes")
    
    # Contexto de triplas relacionadas
    context_parts = []
    if related_triples:
        related_text = "; ".join([
            f"{t.get('subject')} {t.get('predicate')} {t.get('object')}"
            for t in related_triples[:5]
        ])
        context_parts.append(f"Triplas relacionadas: {related_text}")
    
    if external_context:
        context_parts.append(f"Fonte externa: {external_context[:500]}")
    
    context = " | ".join(context_parts)
    
    # 1. An√°lise principal
    prompt = _build_analysis_prompt(conflict, variants, context)
    
    try:
        response = llm.complete(
            prompt,
            system="Voc√™ √© um √°rbitro de conhecimento imparcial. Responda apenas em JSON v√°lido.",
            json_mode=True,
        )
        
        data = _parse_llm_response(response)
        if not data:
            return ResolutionResult(
                resolved=False,
                confidence=0.0,
                reasoning='LLM indispon√≠vel/sem JSON v√°lido para an√°lise de conflito.',
                needs_human=True,
                strategy='llm_unavailable',
            )

        chosen = data.get("chosen", "").strip()
        confidence = float(data.get("confidence", 0))
        reasoning = data.get("reasoning", "")
        
        # Se incerto, escalar para humano
        if chosen.upper() == "INCERTO" or confidence < AUTO_RESOLVE_THRESHOLD:
            return ResolutionResult(
                resolved=False,
                confidence=confidence,
                reasoning=reasoning,
                needs_human=True,
                strategy="llm_analysis_uncertain",
            )
        
        # Verifica se o chosen est√° nas variantes
        variant_objects = [v.get("object", "").strip().lower() for v in variants]
        if chosen.lower() not in variant_objects:
            # LLM pode ter proposto uma s√≠ntese
            return ResolutionResult(
                resolved=False,
                reasoning=f"LLM sugeriu '{chosen}' que n√£o est√° nas variantes",
                needs_human=True,
                strategy="llm_synthesis_suggested",
            )

        # Encontra o objeto exato (case-sensitive)
        exact_chosen = None
        chosen_variant = None
        for v in variants:
            if v.get("object", "").strip().lower() == chosen.lower():
                exact_chosen = v.get("object", "").strip()
                chosen_variant = v
                break

        # Ajuste por coer√™ncia global e trust de fonte
        consistency = 0.5
        if related_triples:
            objl = (exact_chosen or "").lower()
            hits = 0
            for t in related_triples[:12]:
                txt = f"{t.get('subject','')} {t.get('predicate','')} {t.get('object','')}".lower()
                if objl and objl in txt:
                    hits += 1
            consistency = min(1.0, 0.4 + hits * 0.12)

        source_trust = float((chosen_variant or {}).get("source_trust") or 0.5)
        combined_conf = (0.55 * confidence) + (0.25 * source_trust) + (0.20 * consistency)

        return ResolutionResult(
            resolved=combined_conf >= AUTO_RESOLVE_THRESHOLD,
            chosen_object=exact_chosen,
            confidence=combined_conf,
            reasoning=f"{reasoning} | trust_fonte={source_trust:.2f} | coer√™ncia_global={consistency:.2f}",
            strategy="llm_analysis_weighted",
            needs_human=combined_conf < AUTO_RESOLVE_THRESHOLD,
        )
        
    except Exception as e:
        return ResolutionResult(
            resolved=False,
            error=f"Erro na an√°lise LLM: {str(e)[:200]}",
            needs_human=True,
            strategy='llm_exception',
            reasoning='Falha de an√°lise autom√°tica; requer revis√£o humana ou fallback.',
        )


def try_synthesis(conflict: dict, variants: list[dict]) -> ResolutionResult:
    """Tenta sintetizar variantes conflitantes em uma √∫nica resposta."""
    if len(variants) < 2:
        return ResolutionResult(resolved=False, error="Menos de 2 variantes")
    
    prompt = _build_synthesis_prompt(conflict, variants)
    
    try:
        response = llm.complete(
            prompt,
            system="Voc√™ √© um sintetizador de conhecimento. Responda apenas em JSON v√°lido.",
            json_mode=True,
        )
        
        data = _parse_llm_response(response)
        
        can_synthesize = data.get("can_synthesize", False)
        synthesis = data.get("synthesis", "").strip()
        reasoning = data.get("reasoning", "")
        
        if can_synthesize and synthesis:
            return ResolutionResult(
                resolved=True,
                chosen_object=synthesis,
                confidence=0.75,
                reasoning=f"S√≠ntese: {reasoning}",
                strategy="llm_synthesis",
            )
        
        return ResolutionResult(
            resolved=False,
            reasoning=f"Variantes exclusivas: {reasoning}",
            strategy="synthesis_failed",
        )
        
    except Exception as e:
        return ResolutionResult(
            resolved=False,
            error=f"Erro na s√≠ntese: {str(e)[:200]}",
        )


class ConflictResolver:
    """Gerencia resolu√ß√£o autom√°tica de conflitos."""
    
    def __init__(self, store):
        self.store = store
        self._last_attempt: dict[int, float] = {}  # conflict_id -> timestamp
    
    def _can_attempt(self, conflict_id: int) -> bool:
        """Verifica se pode tentar resolver este conflito (cooldown)."""
        last = self._last_attempt.get(conflict_id, 0)
        elapsed_hours = (time.time() - last) / 3600
        return elapsed_hours >= RETRY_COOLDOWN_HOURS
    
    def _record_attempt(self, conflict_id: int):
        """Registra tentativa de resolu√ß√£o."""
        self._last_attempt[conflict_id] = time.time()
    
    def _get_related_triples(self, subject: str, limit: int = 10) -> list[dict]:
        """Busca triplas relacionadas ao sujeito do conflito."""
        return self.store.search_triples(subject, limit=limit)
    
    def resolve_pending(self, max_conflicts: int = MAX_CONFLICTS_PER_CYCLE, force: bool = False) -> list[dict]:
        """Tenta resolver conflitos pendentes.
        
        Returns:
            Lista de resultados de resolu√ß√£o
        """
        results = []
        conflicts = self.store.list_conflicts(status="open", limit=max_conflicts * 2)
        
        resolved_count = 0
        for c in conflicts:
            if resolved_count >= max_conflicts:
                break
            
            cid = int(c.get("id"))
            
            # Verifica cooldown (ou for√ßa tentativa)
            if (not force) and (not self._can_attempt(cid)):
                continue
            
            # Busca detalhes completos
            full = self.store.get_conflict(cid)
            if not full:
                continue
            
            variants = full.get("variants", [])
            if len(variants) < 2:
                continue
            
            self._record_attempt(cid)
            
            # Busca triplas relacionadas para contexto
            subject = full.get("subject", "")
            related = self._get_related_triples(subject)
            
            # Tenta an√°lise primeiro
            result = analyze_conflict(full, variants, related_triples=related)
            
            # Se incerto, tenta s√≠ntese
            if not result.resolved and not result.needs_human:
                result = try_synthesis(full, variants)
            
            # Registra resultado
            result_info = {
                "conflict_id": cid,
                "subject": subject,
                "predicate": full.get("predicate"),
                "resolved": result.resolved,
                "chosen": result.chosen_object,
                "confidence": result.confidence,
                "reasoning": result.reasoning,
                "strategy": result.strategy,
                "needs_human": result.needs_human,
                "error": result.error,
            }
            results.append(result_info)
            
            # Se resolveu, aplica
            if result.resolved and result.chosen_object:
                try:
                    self.store.resolve_conflict(
                        cid,
                        resolution=result.reasoning,
                        chosen_object=result.chosen_object,
                        decided_by=f"auto:{result.strategy}",
                        notes=f"Confian√ßa: {result.confidence:.2f}",
                    )
                    resolved_count += 1
                    
                    # Registra evento
                    self.store.add_event(
                        "conflict_auto_resolved",
                        f"ü§ñ Conflito #{cid} resolvido: {subject} ‚Üí {result.chosen_object} ({result.strategy})",
                    )
                except Exception as e:
                    result_info["error"] = f"Falha ao aplicar: {str(e)[:100]}"
            
            elif result.needs_human:
                # Registra que precisa de humano
                self.store.add_event(
                    "conflict_needs_human",
                    f"üë§ Conflito #{cid} precisa de revis√£o humana: {result.reasoning[:100]}",
                )
        
        return results
